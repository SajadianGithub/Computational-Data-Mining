{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"The_Five_Orange_Pips.txt\", \"r\", encoding='utf8')\n",
    "whole_text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "digits = \"([0-9])\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    if \"...\" in text: text = text.replace(\"...\",\"<prd><prd><prd>\")\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = split_into_sentences(whole_text)\n",
    "data_frame_column = all_sentence.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#library that contains punctuation\n",
    "import string\n",
    "\n",
    "print(type(string.punctuation))\n",
    "\n",
    "#defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "for i in range(len(all_sentence)):\n",
    "    all_sentence[i] = remove_punctuation(all_sentence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_sentence)):\n",
    "    all_sentence[i] = all_sentence[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    tokens = re.split('\\W+',text)\n",
    "    return tokens\n",
    "#applying function to the column\n",
    "for i in range(len(all_sentence)):\n",
    "    all_sentence[i] = tokenization(all_sentence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nlp library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#Stop words present in the library\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "#applying the function\n",
    "for i in range(len(all_sentence)):\n",
    "    all_sentence[i] = remove_stopwords(all_sentence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the Stemming function from nltk library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#defining the object for stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "#defining a function for stemming\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text\n",
    "for i in range(len(all_sentence)):\n",
    "    all_sentence[i] = stemming(all_sentence[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "# for i in range(len(all_sentence)):\n",
    "#     all_sentence[i] = lemmatizer(all_sentence[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "words = list(itertools.chain.from_iterable(all_sentence))\n",
    "nump_words = np.array(words)\n",
    "uniq_words = np.unique(nump_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_word = np.zeros((len(uniq_words), len(all_sentence)))\n",
    "\n",
    "import math\n",
    "\n",
    "def frequently_words (wor, sent):\n",
    "    repetition = 0\n",
    "    for wo in sent:\n",
    "        if (wo == wor):\n",
    "            repetition += 1\n",
    "    return(repetition)\n",
    "\n",
    "def is_there (wor, all_sent):\n",
    "    ni = 0\n",
    "    for sen in all_sent:\n",
    "        for wo in sen:\n",
    "            if (wo == wor):\n",
    "                ni += 1\n",
    "                break\n",
    "    return(ni)\n",
    "\n",
    "row_num = len(uniq_words)\n",
    "col_num = len(all_sentence)\n",
    "\n",
    "text_word = np.zeros((row_num, col_num))\n",
    "for i in range(row_num):\n",
    "    for j in range(col_num):\n",
    "        text_word[i,j] = frequently_words(uniq_words[i], all_sentence[j]) * math.log(col_num/ is_there(uniq_words[i], all_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vt = np.linalg.svd(text_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0372589  0.00021403 0.00169323 ... 0.05063434 0.00863236 0.00119039]\n"
     ]
    }
   ],
   "source": [
    "print(U[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_important_vocabulary (vocabs, scores_arg, num):\n",
    "    if (num > len(vocabs)):\n",
    "        print(\"Error!! Greater than the number of vocabularies\")\n",
    "    else:\n",
    "        for i in range(1, num+1):\n",
    "            print('The vocabulary number ' + str(i) + ' is:: ', vocabs[scores_arg[-i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary number 1 is::  one\n",
      "The vocabulary number 2 is::  would\n",
      "The vocabulary number 3 is::  adventur\n",
      "The vocabulary number 4 is::  upon\n",
      "The vocabulary number 5 is::  man\n",
      "The vocabulary number 6 is::  fact\n",
      "The vocabulary number 7 is::  like\n",
      "The vocabulary number 8 is::  k\n",
      "The vocabulary number 9 is::  case\n",
      "The vocabulary number 10 is::  among\n",
      "The vocabulary number 11 is::  never\n",
      "The vocabulary number 12 is::  connect\n",
      "The vocabulary number 13 is::  singular\n",
      "The vocabulary number 14 is::  societi\n",
      "The vocabulary number 15 is::  final\n",
      "The vocabulary number 16 is::  account\n",
      "The vocabulary number 17 is::  time\n",
      "The vocabulary number 18 is::  day\n",
      "The vocabulary number 19 is::  room\n",
      "The vocabulary number 20 is::  howev\n",
      "The vocabulary number 21 is::  furnitur\n",
      "The vocabulary number 22 is::  british\n",
      "The vocabulary number 23 is::  warehous\n",
      "The vocabulary number 24 is::  loss\n",
      "The vocabulary number 25 is::  lower\n",
      "The vocabulary number 26 is::  luxuri\n",
      "The vocabulary number 27 is::  uffa\n",
      "The vocabulary number 28 is::  grice\n",
      "The vocabulary number 29 is::  poison\n",
      "The vocabulary number 30 is::  paradol\n",
      "The vocabulary number 31 is::  vault\n",
      "The vocabulary number 32 is::  mendic\n",
      "The vocabulary number 33 is::  paterson\n",
      "The vocabulary number 34 is::  camberwel\n",
      "The vocabulary number 35 is::  sophi\n",
      "The vocabulary number 36 is::  anderson\n",
      "The vocabulary number 37 is::  island\n",
      "The vocabulary number 38 is::  amateur\n",
      "The vocabulary number 39 is::  holm\n",
      "The vocabulary number 40 is::  held\n",
      "The vocabulary number 41 is::  abl\n",
      "The vocabulary number 42 is::  twelv\n",
      "The vocabulary number 43 is::  may\n",
      "The vocabulary number 44 is::  head\n",
      "The vocabulary number 45 is::  find\n",
      "The vocabulary number 46 is::  chamber\n",
      "The vocabulary number 47 is::  paper\n",
      "The vocabulary number 48 is::  bark\n",
      "The vocabulary number 49 is::  month\n",
      "The vocabulary number 50 is::  club\n"
     ]
    }
   ],
   "source": [
    "display_important_vocabulary(uniq_words, np.argsort(U[:,0]), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1447,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.06992634e-18 -3.05825034e-18 -2.26160797e-18 -3.00926554e-36\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.81426913e-21\n",
      "  5.62905005e-21  9.97860727e-21  1.81039295e-20  2.24874013e-19\n",
      "  2.71991927e-19  8.17292488e-19  1.10593404e-18  1.45089224e-18\n",
      "  3.42840376e-05  2.04725129e-04  2.20604247e-04  4.43418053e-04\n",
      "  4.43418053e-04  4.43418053e-04  4.94597519e-04  5.27380975e-04\n",
      "  5.34793833e-04  5.42267018e-04  5.97014024e-04  6.31696032e-04\n",
      "  8.00806434e-04  9.59441008e-04  1.03087167e-03  1.03781514e-03\n",
      "  1.17880627e-03  1.19492583e-03  1.23894585e-03  1.24411177e-03\n",
      "  1.29179265e-03  1.36670930e-03  1.55242042e-03  1.67318294e-03\n",
      "  1.72001529e-03  1.75088907e-03  1.79799379e-03  1.89995470e-03\n",
      "  1.94888081e-03  1.94888081e-03  1.94888081e-03  2.17541774e-03\n",
      "  2.20056385e-03  2.24194872e-03  2.25411876e-03  2.26267775e-03\n",
      "  2.36049618e-03  2.39951586e-03  2.62478363e-03  2.67152828e-03\n",
      "  2.70085195e-03  2.72586445e-03  2.79987466e-03  2.79987466e-03\n",
      "  2.79987466e-03  2.92603636e-03  3.03283309e-03  3.03283309e-03\n",
      "  3.03283309e-03  3.04026273e-03  3.20639797e-03  3.25039488e-03\n",
      "  3.28839615e-03  3.31424502e-03  3.32914460e-03  3.43950970e-03\n",
      "  3.55876792e-03  3.60610618e-03  3.75811710e-03  3.83781636e-03\n",
      "  3.87097387e-03  3.99171612e-03  3.99640129e-03  4.04707261e-03\n",
      "  4.35140286e-03  4.42260764e-03  4.43636811e-03  4.48337699e-03\n",
      "  4.52753495e-03  4.53040144e-03  4.54716489e-03  4.60591152e-03\n",
      "  4.63266187e-03  4.67189471e-03  4.72366885e-03  4.76317248e-03\n",
      "  4.79164066e-03  4.92353166e-03  4.94817258e-03  4.96496262e-03\n",
      "  4.98495637e-03  4.99976808e-03  5.02913352e-03  5.05422464e-03\n",
      "  5.06031247e-03  5.14494125e-03  5.17576782e-03  5.18716222e-03\n",
      "  5.26457654e-03  5.27167092e-03  5.29449851e-03  5.46791724e-03\n",
      "  5.56213045e-03  5.75254489e-03  5.78057589e-03  5.78057589e-03\n",
      "  5.78057589e-03  5.98530102e-03  6.10651514e-03  6.15907801e-03\n",
      "  6.27362907e-03  6.28744783e-03  6.36474177e-03  6.38139136e-03\n",
      "  6.40815601e-03  6.41862537e-03  6.52132944e-03  6.62090528e-03\n",
      "  6.74185409e-03  6.95022512e-03  6.95274493e-03  7.10132874e-03\n",
      "  7.18468865e-03  7.21114994e-03  7.22090195e-03  7.23191095e-03\n",
      "  7.39718009e-03  7.40846018e-03  7.47500260e-03  7.49271603e-03\n",
      "  7.57250476e-03  7.69333058e-03  7.93634291e-03  7.94453517e-03\n",
      "  8.11421807e-03  8.16489924e-03  8.18224883e-03  8.27638465e-03\n",
      "  8.43483363e-03  8.45545354e-03  8.60766137e-03  8.64756733e-03\n",
      "  8.65876372e-03  8.79189327e-03  8.86680321e-03  8.90281845e-03\n",
      "  8.94016776e-03  8.96355008e-03  9.04963518e-03  9.31956039e-03\n",
      "  9.52291168e-03  9.65447961e-03  9.67530212e-03  9.68787065e-03\n",
      "  9.70893776e-03  9.80992186e-03  9.92587388e-03  1.00543100e-02\n",
      "  1.01476729e-02  1.02196023e-02  1.02896837e-02  1.03428274e-02\n",
      "  1.04517487e-02  1.05617665e-02  1.08015677e-02  1.08282634e-02\n",
      "  1.08842500e-02  1.10701133e-02  1.11841020e-02  1.13672473e-02\n",
      "  1.14167099e-02  1.14623997e-02  1.15379537e-02  1.15639734e-02\n",
      "  1.17103246e-02  1.17153681e-02  1.17196307e-02  1.18503319e-02\n",
      "  1.18867587e-02  1.19114293e-02  1.19868056e-02  1.19981601e-02\n",
      "  1.20064881e-02  1.20947671e-02  1.22799791e-02  1.22988774e-02\n",
      "  1.24568113e-02  1.25624603e-02  1.28027921e-02  1.28423518e-02\n",
      "  1.31447380e-02  1.33612488e-02  1.34067755e-02  1.39084068e-02\n",
      "  1.39744603e-02  1.40420091e-02  1.40512164e-02  1.42670368e-02\n",
      "  1.42992150e-02  1.44539742e-02  1.46528923e-02  1.47717602e-02\n",
      "  1.48901686e-02  1.49730483e-02  1.50668414e-02  1.51671555e-02\n",
      "  1.52046263e-02  1.53935441e-02  1.55690990e-02  1.55940692e-02\n",
      "  1.56114415e-02  1.56255850e-02  1.57034200e-02  1.59016231e-02\n",
      "  1.59357932e-02  1.59670234e-02  1.62721991e-02  1.62864496e-02\n",
      "  1.63229194e-02  1.63423485e-02  1.63859207e-02  1.64465690e-02\n",
      "  1.64538213e-02  1.64671418e-02  1.65825843e-02  1.65892396e-02\n",
      "  1.66321026e-02  1.67636283e-02  1.69382344e-02  1.71023957e-02\n",
      "  1.71213239e-02  1.72340446e-02  1.74879648e-02  1.74928555e-02\n",
      "  1.76919533e-02  1.79142252e-02  1.79164314e-02  1.82202168e-02\n",
      "  1.82695037e-02  1.83474151e-02  1.84703463e-02  1.85005350e-02\n",
      "  1.85557541e-02  1.90095578e-02  1.91209268e-02  1.92061140e-02\n",
      "  1.93561342e-02  1.96335702e-02  1.97003540e-02  1.98235565e-02\n",
      "  1.98540463e-02  2.01958934e-02  2.02074849e-02  2.05746181e-02\n",
      "  2.06568425e-02  2.06896170e-02  2.06897928e-02  2.07381335e-02\n",
      "  2.08469935e-02  2.09842247e-02  2.10879610e-02  2.11042440e-02\n",
      "  2.15273179e-02  2.15819285e-02  2.17420263e-02  2.17675616e-02\n",
      "  2.17840524e-02  2.18086212e-02  2.18973454e-02  2.20329722e-02\n",
      "  2.23567249e-02  2.24597501e-02  2.26112927e-02  2.26326362e-02\n",
      "  2.26357024e-02  2.26369695e-02  2.28551172e-02  2.34751589e-02\n",
      "  2.35719875e-02  2.37947189e-02  2.39173879e-02  2.39760359e-02\n",
      "  2.40759322e-02  2.44118247e-02  2.46247970e-02  2.48302025e-02\n",
      "  2.49785239e-02  2.50974575e-02  2.51845731e-02  2.52472662e-02\n",
      "  2.52846827e-02  2.53916927e-02  2.55403275e-02  2.55640262e-02\n",
      "  2.56066025e-02  2.56122412e-02  2.57118151e-02  2.58341568e-02\n",
      "  2.58795643e-02  2.60994448e-02  2.61134734e-02  2.65655136e-02\n",
      "  2.65779074e-02  2.67988271e-02  2.71449174e-02  2.72577546e-02\n",
      "  2.74736316e-02  2.77452970e-02  2.79941555e-02  2.82771100e-02\n",
      "  2.86157621e-02  2.89834365e-02  2.90830292e-02  2.93839011e-02\n",
      "  2.98891959e-02  2.99561374e-02  3.01495035e-02  3.01957293e-02\n",
      "  3.02284786e-02  3.06410411e-02  3.10638250e-02  3.12418860e-02\n",
      "  3.13206569e-02  3.16148198e-02  3.17807741e-02  3.21489161e-02\n",
      "  3.23611711e-02  3.26684848e-02  3.28148729e-02  3.32794910e-02\n",
      "  3.36981353e-02  3.38779341e-02  3.40016531e-02  3.43512136e-02\n",
      "  3.46187466e-02  3.50791135e-02  3.51091731e-02  3.52440170e-02\n",
      "  3.53733434e-02  3.55041070e-02  3.57884145e-02  3.59365459e-02\n",
      "  3.60054433e-02  3.61681119e-02  3.63011593e-02  3.63209504e-02\n",
      "  3.65183138e-02  3.68777563e-02  3.74763727e-02  3.79674647e-02\n",
      "  3.79785538e-02  3.82957536e-02  3.83320138e-02  3.83831931e-02\n",
      "  3.91250167e-02  4.00528150e-02  4.00762714e-02  4.03338254e-02\n",
      "  4.04220361e-02  4.10393118e-02  4.11537548e-02  4.14246888e-02\n",
      "  4.15040727e-02  4.15041866e-02  4.16483734e-02  4.19942105e-02\n",
      "  4.21645074e-02  4.22256287e-02  4.29251763e-02  4.30378649e-02\n",
      "  4.36441073e-02  4.38156726e-02  4.39259837e-02  4.39417972e-02\n",
      "  4.41314125e-02  4.44396067e-02  4.48776455e-02  4.61873012e-02\n",
      "  4.66012312e-02  4.66790478e-02  4.66955471e-02  4.77917705e-02\n",
      "  4.79980589e-02  4.80203320e-02  4.88819114e-02  4.93897891e-02\n",
      "  4.95089358e-02  4.96400617e-02  4.97229571e-02  5.09508254e-02\n",
      "  5.11704511e-02  5.18656914e-02  5.21010647e-02  5.27722219e-02\n",
      "  5.34349389e-02  5.35274300e-02  5.37911116e-02  5.40293062e-02\n",
      "  5.52114374e-02  5.57078781e-02  5.57587214e-02  5.59250472e-02\n",
      "  5.66606213e-02  6.04547335e-02  6.07022845e-02  6.10179796e-02\n",
      "  6.16002907e-02  6.21174952e-02  6.35534475e-02  6.36864964e-02\n",
      "  6.47968346e-02  6.54769920e-02  6.60317417e-02  6.61216206e-02\n",
      "  6.64239147e-02  6.68712788e-02  6.69913318e-02  6.79043095e-02\n",
      "  6.97023322e-02  7.07760248e-02  7.13216125e-02  7.15046030e-02\n",
      "  7.42181439e-02  7.56850541e-02  7.59581154e-02  7.78842592e-02\n",
      "  7.92159904e-02  7.93317745e-02  8.04914884e-02  8.60321213e-02\n",
      "  8.79750173e-02  9.25690918e-02  9.54693943e-02  9.56906792e-02\n",
      "  9.59552002e-02  1.00333614e-01  1.03230383e-01  1.03815597e-01\n",
      "  1.06199116e-01  1.09120060e-01  1.12909618e-01  1.15518451e-01\n",
      "  1.20826419e-01  1.30820453e-01  1.37642373e-01  1.38207567e-01\n",
      "  1.46164330e-01  1.48902338e-01  1.73389889e-01  1.92396719e-01\n",
      "  2.78661069e-01  5.16675817e-01]\n"
     ]
    }
   ],
   "source": [
    "print(Vt[0,:][np.argsort(Vt[0,:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 419, 235,  38,  83, 319,  85, 454, 211, 447, 288, 335, 196,\n",
       "       197, 415, 317,  43, 207, 203,  18, 384, 459, 233, 231, 423, 450,\n",
       "        30, 307, 240, 126,  17, 375, 218, 179, 428, 342, 438, 127, 334,\n",
       "        44, 437, 340, 407, 252, 432, 148, 320, 406, 421, 380, 268, 145,\n",
       "       208, 341, 143, 440, 245, 386,  39, 273, 215, 316, 416, 403, 318,\n",
       "       204, 140, 164, 152, 202, 192, 418, 191, 298,  35, 149, 253, 336,\n",
       "        49, 408, 287, 260, 161, 397, 265, 378, 284, 325, 165, 379, 263,\n",
       "       229, 238, 315, 185, 374, 226,  92,  40, 261, 402,  55, 230, 189,\n",
       "       200, 267, 286, 414, 445, 264,  25, 367, 354, 144, 457,  50, 324,\n",
       "        15, 239, 269, 422, 283, 247,  24, 225, 105, 195, 417, 427, 154,\n",
       "       163, 186,  51,  37, 139,  91, 300,  16,  87, 282, 159, 213, 446,\n",
       "        46, 424, 158, 141, 234, 327,  54, 210, 162, 155, 201, 153, 256,\n",
       "       170,  13, 272, 431, 302, 456, 147, 383, 439, 250, 156,  90, 266,\n",
       "       212, 190, 257, 434, 124, 271, 259, 160, 349, 157,  19, 313, 412,\n",
       "       351, 150, 377, 236, 280,  34, 275,  41, 299, 409, 244, 387, 303,\n",
       "       396, 294, 430, 353,  96, 381, 346, 232,  14, 420,  45, 321, 216,\n",
       "       293, 449, 347, 214, 178, 314, 364, 391,  57, 404, 435,  84,  21,\n",
       "       129, 108,  47, 443, 166, 198, 104, 385, 169, 151, 254, 193,  29,\n",
       "        66, 167, 462, 199, 365, 262, 103, 451,  33, 206, 330, 131, 326,\n",
       "       312, 255, 322,  53, 146, 401, 455, 177,  32, 436, 100,  76, 452,\n",
       "        56,  63, 246, 328, 399, 361, 372, 109,  42, 173,  95,  71, 395,\n",
       "       405, 243, 425, 228,  12,  36, 241, 174, 123, 394, 224, 107,  52,\n",
       "       458,  82,  89, 120, 410, 217, 276, 356, 358, 112, 106, 176,  67,\n",
       "       411,   8,  69, 242,  62, 464, 441, 308, 371, 258, 209,  68,  59,\n",
       "       376, 433, 332, 251, 426, 362, 465, 352, 119, 453, 113, 219, 270,\n",
       "       343,  60,  99,  70, 413, 133,  31,  48, 281, 333, 118,  98, 285,\n",
       "       388, 227, 463, 337, 382, 125,  75, 221, 188, 220, 171,  10,  93,\n",
       "       398, 138, 248, 101,  26, 390, 134, 344, 194, 329, 366, 187, 297,\n",
       "       289, 331, 121,  61, 172, 277, 429, 128, 323,  78,  23, 305, 136,\n",
       "       309, 290, 448, 310,  58,  27,  22, 368, 116, 182,  86,  64,  65,\n",
       "       306, 373, 339, 135,   4, 338, 183, 392, 274, 345, 205, 181, 249,\n",
       "        20, 400, 311,  74,   1, 222, 363, 301, 142, 389, 350,   7, 102,\n",
       "        88, 370, 359, 122,  81, 111,  77, 442, 460, 355,  94, 296,  28,\n",
       "       348, 279, 357,  73, 184, 175, 393, 132,  80, 137, 360, 444, 278,\n",
       "         0, 130, 168, 110,  97, 117, 304, 291,   2, 180, 115, 292, 461,\n",
       "       223,  72, 295,   6, 369,  79,   3,  11,   9, 114,   5], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(Vt[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_important_sentences (sentences, scores_arg, num):\n",
    "    if (num > len(sentences)):\n",
    "        print(\"Error!! Greater than the number of sentences\")\n",
    "    else:\n",
    "        for i in range(1, num+1):\n",
    "            print('The sentence number ' + str(i) + ' is:')\n",
    "            print(sentences[scores_arg[-i]])\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence number 1 is:\n",
      "Among my headings under this one twelve months I find an account of the adventure of the Paradol Chamber, of the Amateur Mendicant Society, who held a luxurious club in the lower vault of a furniture warehouse, of the facts connected with the loss of the British bark Sophy Anderson, of the singular adventures of the Grice Patersons in the island of Uffa, and finally of the Camberwell poisoning case.\n",
      "\n",
      "The sentence number 2 is:\n",
      "Most of his time he would spend in his room, with the door locked upon the inside, but sometimes he would emerge in a sort of drunken frenzy and would burst out of the house and tear about the garden with a revolver in his hand, screaming out that he was afraid of no man, and that he was not to be cooped up, like a sheep in a pen, by man or devil.\n",
      "\n",
      "The sentence number 3 is:\n",
      "All day the wind had screamed and the rain had beaten against the windows, so that even here in the heart of great, hand-made London we were forced to raise our minds for the instant from the routine of life and to recognize the presence of those great elemental forces which shriek at mankind through the bars of his civilization, like untamed beasts in a cage.\n",
      "\n",
      "The sentence number 4 is:\n",
      "Sherlock Holmes sat moodily at one side of the fireplace cross-indexing his records of crime, while I at the other was deep in one of Clark Russell's fine sea-stories until the howl of the gale from without seemed to blend with the text, and the splash of the rain to lengthen out into the long swash of the sea waves.\n",
      "\n",
      "The sentence number 5 is:\n",
      "There is, however, one of these last which was so remark- able in its details and so startling in its results that I am tempted to give some account of it in spite of the fact that there are points in connection with it which never have been, and probably never will be, entirely cleared up.\n",
      "\n",
      "The sentence number 6 is:\n",
      "There was one singular exception, however, for he had a single room, a lumber-room up among the attics, which was invariably locked, and which he would never permit either me or anyone else to enter.\n",
      "\n",
      "The sentence number 7 is:\n",
      "Then there are successive entries that A and B cleared, or left the country, and finally that C was visited, with, I fear, a sinister result for C. Well, I think, Doctor, that we may let some light into this dark place, and I believe that the only chance young Openshaw has in the meantime is to do what I have told him.\n",
      "\n",
      "The sentence number 8 is:\n",
      "In the latter, as may be remembered, Sherlock Holmes was able, by winding up the dead man's watch, to prove that it had been wound up two hours before, and that therefore the deceased had gone to bed within that time -- a deduction which was of the greatest importance in clearing up the case.\n",
      "\n",
      "The sentence number 9 is:\n",
      "To carry the art, however, to its highest pitch, it is necessary that the reasoner should be able to utilize all the facts which have come to his knowledge; and this in itself implies, as you will readily see, a possession of all knowledge, which, even in these days of free education and encyclopaedias, is a somewhat rare accomplishment.\n",
      "\n",
      "The sentence number 10 is:\n",
      "He had a garden and two or three fields round his house, and there he would take his exercise, though very often for weeks on end he would never leave his room.\n",
      "\n",
      "The sentence number 11 is:\n",
      "I found this single sheet upon the floor of his room, and I am inclined to think that it may be one of the papers which has, perhaps, fluttered out from among the others, and in that way has escaped destruction.\n",
      "\n",
      "The sentence number 12 is:\n",
      "There is ever a flaw, however, in the best laid of human plans, and the murderers of John Openshaw were never to receive the orange pips which would show them that another, as cunning and as resolute as themselves, was upon their track.\n",
      "\n",
      "The sentence number 13 is:\n",
      "As Cuvier could correctly describe a whole animal by the contemplation of a single bone, so the observer who has thoroughly understood one link in a series of incidents should be able to accurately state all the other ones, both before and after.\n",
      "\n",
      "The sentence number 14 is:\n",
      "When these hot fits were over however, he would rush tumultuously in at the door and lock and bar it behind him, like a man who can brazen it out no longer against the terror which lies at the roots of his soul.\n",
      "\n",
      "The sentence number 15 is:\n",
      "I answer, because I was well convinced that our troubles were in some way dependent upon an incident in my uncle's life, and that the danger would be as pressing in one house as in another.\n",
      "\n",
      "The sentence number 16 is:\n",
      "Some, too, have baffled his analytical skill, and would be, as narratives, beginnings without an ending, while others have been but partially cleared up, and have their explanations founded rather upon conjecture and sur- mise than on that absolute logical proof which was so dear to him.\n",
      "\n",
      "The sentence number 17 is:\n",
      "\"The ideal reasoner,\" he remarked, \"would, when he had once been shown a single fact in all its bearings, deduce from it not only all the chain of events which led up to it but also all the results which would follow from it.\n",
      "\n",
      "The sentence number 18 is:\n",
      "\"Well,\" he said, \"I say now, as I said then, that a man should keep his little brain-attic stocked with all the furniture that he is likely to use, and the rest he can put away in the lumber-room of his library, where he can get it if he wants it.\n",
      "\n",
      "The sentence number 19 is:\n",
      "\"Well, to come to an end of the matter, Mr. Holmes, and not to abuse your patience, there came a night when he made one of those drunken sallies from which he never came back.\n",
      "\n",
      "The sentence number 20 is:\n",
      "I left the breakfast-table, and as I ascended the stair I met him coming down with an old rusty key, which must have belonged to the attic, in one hand, and a small brass box, like a cashbox, in the other.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_important_sentences(data_frame_column, np.argsort(Vt[0,:]), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def house_holder(x_vector, dim):\n",
    "    x_vector = list(x_vector)\n",
    "    x = np.array(x_vector).reshape(-1,1)\n",
    "    w = x/np.linalg.norm(x)\n",
    "\n",
    "    e = np.zeros_like(x)\n",
    "    e[0,0] = 1\n",
    "    if (x[0,0] != 0):\n",
    "        v = np.sign(x[0,0]) * e\n",
    "    else:\n",
    "        v = e\n",
    "\n",
    "    small_u = (w - v)/ np.linalg.norm(w - v)\n",
    "\n",
    "    u = np.zeros((dim,1))\n",
    "    for i in range(len(small_u)):\n",
    "        u[-i-1,0] = small_u[-i-1,0]\n",
    "\n",
    "    i = np.diag(np.ones(dim))\n",
    "    h = i - (u @ u.T)* 2#/np.linalg.norm(u @ u.T))\n",
    "\n",
    "    return(h)\n",
    "\n",
    "def change_col (A, col1, col2):\n",
    "    a = np.zeros_like(A)\n",
    "    m, n = A.shape\n",
    "    for i in range(n):\n",
    "        if (i != col1 and i != col2):\n",
    "            a[:,i] = A[:,i]\n",
    "    a[:,col1] = A[:,col2]\n",
    "    a[:,col2] = A[:,col1]\n",
    "    return(a)\n",
    "\n",
    "\n",
    "data_frame_column_copyy = data_frame_column.copy()\n",
    "data_frame_column_copyy = np.array(data_frame_column_copyy).reshape(1,-1)\n",
    "data_frame_column_indexx = range(len(data_frame_column))\n",
    "data_frame_column_indexx = np.array(data_frame_column_indexx).reshape(1,-1)\n",
    "\n",
    "\n",
    "def extraction (A, num_sen, data_frame_column_index, data_frame_column_copy):\n",
    "\n",
    "    m, n = A.shape\n",
    "    model = NMF(n_components=num_sen+1, init='random', random_state=0)\n",
    "    W = model.fit_transform(A)\n",
    "    H = model.components_\n",
    "\n",
    "\n",
    "    k, n = H.shape\n",
    "\n",
    "    for i in range(num_sen):\n",
    "        dict_norms = {}\n",
    "        for j in range (n):\n",
    "            dict_norms[j] = np.linalg.norm(H[i:, j])\n",
    "\n",
    "        max_norm = max(dict_norms.values())\n",
    "        if (math.isnan(max_norm)):\n",
    "            print(\"Error!! This computer cannot calculate more than  \"+ str(i) + \" sentence\")\n",
    "            break\n",
    "\n",
    "        for key in dict_norms.keys():\n",
    "            if (dict_norms[key] == max_norm):\n",
    "                high_sent = key \n",
    "\n",
    "        H = change_col(H, i, high_sent)\n",
    "        data_frame_column_copy = change_col(data_frame_column_copy, i, high_sent)\n",
    "        data_frame_column_index = change_col(data_frame_column_index, i, high_sent)\n",
    "        A = change_col(A, i, high_sent)\n",
    "\n",
    "        q = house_holder(H[i:,i], k)\n",
    "        H = q @ H\n",
    "        W = W @ q\n",
    "\n",
    "    return (data_frame_column_index[0, :i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295 311 301 355 114 369   5   6   9 130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hosein\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\decomposition\\_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scorelist = extraction(text_word, 11, data_frame_column_indexx, data_frame_column_copyy)\n",
    "print(scorelist)\n",
    "scorelist = list(scorelist)\n",
    "scorelist.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence number 1 is:\n",
      "To carry the art, however, to its highest pitch, it is necessary that the reasoner should be able to utilize all the facts which have come to his knowledge; and this in itself implies, as you will readily see, a possession of all knowledge, which, even in these days of free education and encyclopaedias, is a somewhat rare accomplishment.\n",
      "\n",
      "The sentence number 2 is:\n",
      "His extreme love of solitude in England suggests the idea that he was in fear of someone or something, so we may assume as a working hypothesis that it was fear of someone or something which drove him from America.\n",
      "\n",
      "The sentence number 3 is:\n",
      "Botany variable, geology profound as regards the mud-stains from any region within fifty miles of town, chemistry eccentric, anatomy unsystematic, sensational literature and crime records unique, violin-player, boxer, swordsman, lawyer, and self-poisoner by cocaine and tobacco.\n",
      "\n",
      "The sentence number 4 is:\n",
      "This     terrible secret society was formed by some ex-Confederate     soldiers in the Southern states after the Civil War, and it     rapidly formed local branches in different parts of the     country, notably in Tennessee, Louisiana, the Carolinas,     Georgia, and Florida.\n",
      "\n",
      "The sentence number 5 is:\n",
      "Most of his time he would spend in his room, with the door locked upon the inside, but sometimes he would emerge in a sort of drunken frenzy and would burst out of the house and tear about the garden with a revolver in his hand, screaming out that he was afraid of no man, and that he was not to be cooped up, like a sheep in a pen, by man or devil.\n",
      "\n",
      "The sentence number 6 is:\n",
      "Then there are successive entries that A and B cleared, or left the country, and finally that C was visited, with, I fear, a sinister result for C. Well, I think, Doctor, that we may let some light into this dark place, and I believe that the only chance young Openshaw has in the meantime is to do what I have told him.\n",
      "\n",
      "The sentence number 7 is:\n",
      "Among my headings under this one twelve months I find an account of the adventure of the Paradol Chamber, of the Amateur Mendicant Society, who held a luxurious club in the lower vault of a furniture warehouse, of the facts connected with the loss of the British bark Sophy Anderson, of the singular adventures of the Grice Patersons in the island of Uffa, and finally of the Camberwell poisoning case.\n",
      "\n",
      "The sentence number 8 is:\n",
      "In the latter, as may be remembered, Sherlock Holmes was able, by winding up the dead man's watch, to prove that it had been wound up two hours before, and that therefore the deceased had gone to bed within that time -- a deduction which was of the greatest importance in clearing up the case.\n",
      "\n",
      "The sentence number 9 is:\n",
      "All day the wind had screamed and the rain had beaten against the windows, so that even here in the heart of great, hand-made London we were forced to raise our minds for the instant from the routine of life and to recognize the presence of those great elemental forces which shriek at mankind through the bars of his civilization, like untamed beasts in a cage.\n",
      "\n",
      "The sentence number 10 is:\n",
      "On the inside of the cover was a paper label, with the initials of K. K. K. repeated upon it, and 'Letters, memoranda, receipts, and a register' written beneath.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_important_sentences(data_frame_column, scorelist, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a7764e5d00a7218a57bbd60a655505fc2342e727bda0f027b1e5f6d4545df63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
